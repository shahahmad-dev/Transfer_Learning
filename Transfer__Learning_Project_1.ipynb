{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ğŸ”„ **Transfer Learning with TensorFlow**\n",
        "\n",
        "## ğŸ“Œ **What is Transfer Learning?**\n",
        "\n",
        "**Transfer Learning** reuses a **pre-trained model** for a new, related task.  \n",
        "Instead of training from scratch, we adapt knowledge learned from a **large dataset** to a **smaller dataset**.\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ§  **Model: `MobileNetV2`**\n",
        "\n",
        "- Pre-trained on **`ImageNet`**\n",
        "- Lightweight and efficient\n",
        "- Ideal for **image classification**\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ“Š **Dataset: `CIFAR-10`**\n",
        "\n",
        "- ğŸ–¼ï¸ 60,000 images  \n",
        "- ğŸ“ 32 Ã— 32 pixels  \n",
        "- ğŸ·ï¸ 10 classes  \n",
        "\n",
        "---\n",
        "\n",
        "## ğŸš€ **Goal**\n",
        "\n",
        "- Load **`MobileNetV2`**\n",
        "- Replace final layer\n",
        "- Fine-tune on **`CIFAR-10`**\n",
        "- Improve performance\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ’¡ **Why Use It?**\n",
        "\n",
        "- â³ Faster training  \n",
        "- ğŸ“‰ Less data required  \n",
        "- ğŸ“ˆ Better accuracy  \n",
        "\n",
        "> ğŸš€ Transfer Learning helps build powerful vision models efficiently."
      ],
      "metadata": {
        "id": "djZ3TZjze1bL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **`Step 1: Import Libraries and Load Data`**"
      ],
      "metadata": {
        "id": "kZlqmGmwd985"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xqPC16ppaM3-"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Load CIFAR-10 data\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "# Normalize pixel values and convert labels to one-hot encoding\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "y_train, y_test = to_categorical(y_train, 10), to_categorical(y_test, 10)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ğŸ¨ **Data Augmentation**\n",
        "\n",
        "## ğŸ“Œ **What is Data Augmentation?**\n",
        "\n",
        "**Data Augmentation** increases the **size** and **diversity** of training data by creating modified versions of existing data â€” without collecting new samples.\n",
        "\n",
        "Common techniques (for images):\n",
        "\n",
        "- ğŸ”„ **Rotation**\n",
        "- â†”ï¸ **Flipping**\n",
        "- ğŸ” **Scaling / Zooming**\n",
        "- âœ‚ï¸ **Cropping**\n",
        "- ğŸŒ«ï¸ **Adding Noise**\n",
        "- ğŸ¨ **Brightness Adjustment**\n",
        "\n",
        "---\n",
        "\n",
        "## âœ… **Why It Matters**\n",
        "\n",
        "- ğŸ”¥ **Prevents Overfitting** â€“ Improves generalization  \n",
        "- ğŸ“ˆ **Boosts Performance** â€“ More diverse training data  \n",
        "- âš–ï¸ **Handles Imbalance** â€“ Augments minority classes  \n",
        "\n",
        "> âš ï¸ Always choose augmentations that make sense for your task (e.g., avoid flipping text images).\n",
        "\n",
        "---\n",
        "\n",
        "# ğŸ› ï¸ **Step 2: Data Preprocessing**\n",
        "\n",
        "## ğŸ“ **Image Size Adjustment**\n",
        "\n",
        "- **`MobileNetV2`** expects: **224 Ã— 224**\n",
        "- **`CIFAR-10`** images are: **32 Ã— 32**\n",
        "\n",
        "### âœ… Required Steps:\n",
        "\n",
        "- ğŸ”„ **Resize to 224 Ã— 224**\n",
        "- ğŸ¨ Apply **Data Augmentation**\n",
        "- ğŸ“Š **Normalize / Rescale** pixel values\n",
        "\n",
        "---\n",
        "\n",
        "ğŸš€ Proper **Augmentation + Preprocessing** ensures compatibility with **`MobileNetV2`** and improves model performance."
      ],
      "metadata": {
        "id": "cSwz2B3OeYEF"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zsCs3C5MeJcV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}