{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Transfer Learning with TensorFlow**\n",
        "\n",
        "## **What is Transfer Learning?**\n",
        "\n",
        "**Transfer Learning** reuses a **pre-trained model** for a new task.  \n",
        "Instead of training from scratch, we adapt knowledge learned from a **large dataset** to a **smaller dataset**.\n",
        "\n",
        "---\n",
        "\n",
        "## **Model: `MobileNetV2`**\n",
        "\n",
        "- Pre-trained on **`ImageNet`**\n",
        "- Lightweight and efficient\n",
        "- Suitable for **image classification**\n",
        "\n",
        "---\n",
        "\n",
        "## **Dataset: `CIFAR-10`**\n",
        "\n",
        "- 60,000 images  \n",
        "- 32 × 32 pixels  \n",
        "- 10 classes  \n",
        "\n",
        "---\n",
        "\n",
        "## **Goal**\n",
        "\n",
        "- Load **`MobileNetV2`**\n",
        "- Replace the final layer\n",
        "- Fine-tune on **`CIFAR-10`**\n",
        "- Improve performance\n",
        "\n",
        "---\n",
        "\n",
        "## **Why Use Transfer Learning?**\n",
        "\n",
        "- Faster training  \n",
        "- Requires less data  \n",
        "- Better accuracy  \n",
        "\n",
        "Transfer Learning enables efficient and high-performing computer vision models."
      ],
      "metadata": {
        "id": "djZ3TZjze1bL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **`Step 1: Import Libraries and Load Data`**"
      ],
      "metadata": {
        "id": "kZlqmGmwd985"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xqPC16ppaM3-"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Load CIFAR-10 data\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "# Normalize pixel values and convert labels to one-hot encoding\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "y_train, y_test = to_categorical(y_train, 10), to_categorical(y_test, 10)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Data Augmentation**\n",
        "\n",
        "## **What is Data Augmentation?**\n",
        "\n",
        "**Data Augmentation** increases the **size** and **diversity** of training data by creating modified versions of existing data without collecting new samples.\n",
        "\n",
        "Common techniques (for images):\n",
        "\n",
        "- **Rotation**\n",
        "- **Flipping**\n",
        "- **Scaling / Zooming**\n",
        "- **Cropping**\n",
        "- **Adding Noise**\n",
        "- **Brightness Adjustment**\n",
        "\n",
        "---\n",
        "\n",
        "## **Why It Matters**\n",
        "\n",
        "- **Prevents Overfitting** – Improves generalization  \n",
        "- **Boosts Performance** – More diverse training data  \n",
        "- **Handles Imbalance** – Augments minority classes  \n",
        "\n",
        "> Always choose augmentations that make sense for your task (e.g., avoid flipping text images).\n",
        "\n",
        "---\n",
        "\n",
        "# **Step 2: Data Preprocessing**\n",
        "\n",
        "## **Image Size Adjustment**\n",
        "\n",
        "- **`MobileNetV2`** expects: **224 × 224**\n",
        "- **`CIFAR-10`** images are: **32 × 32**\n",
        "\n",
        "### **Required Steps**\n",
        "\n",
        "- **Resize to 224 × 224**\n",
        "- Apply **Data Augmentation**\n",
        "- **Normalize / Rescale** pixel values\n",
        "\n",
        "Proper **Augmentation + Preprocessing** ensures compatibility with **`MobileNetV2`** and improves model performance."
      ],
      "metadata": {
        "id": "cSwz2B3OeYEF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Augmentation\n",
        "datagen = ImageDataGenerator(\n",
        "    featurewise_center = False,\n",
        "    samplewise_center = False,\n",
        "    featurewise_std_normalization = False,\n",
        "    samplewise_std_normalization = False,\n",
        "    zca_whitening = False,\n",
        "    rotation_range = 15,\n",
        "    width_shift_range = 0.1,\n",
        "    height_shift_range = 0.1,\n",
        "    horizontal_flip = True ,\n",
        "    vertical_flip = True,\n",
        "    zoom_range = 0.1,\n",
        "    fill_mode = 'nearest'\n",
        ")\n",
        "\n",
        "datagen.fit(x_train)"
      ],
      "metadata": {
        "id": "zsCs3C5MeJcV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 3: Modify the Pre-Trained Model\n",
        "\n",
        "## Why Modify the Model?\n",
        "\n",
        "MobileNetV2 is pre-trained on ImageNet with 1000 classes.  \n",
        "Our task (CIFAR-10) has only 10 classes, so we must:\n",
        "\n",
        "- Remove the original top layer  \n",
        "- Add a new classifier for 10 classes  \n",
        "- Freeze the base layers (initially)\n",
        "\n",
        "---\n",
        "\n",
        "## What We Do\n",
        "\n",
        "### 1. Load MobileNetV2 Without Top Layer\n",
        "- `include_top=False`\n",
        "- Keep feature extraction layers\n",
        "- Remove the 1000-class classifier\n",
        "\n",
        "### 2. Add New Classifier\n",
        "- Global Average Pooling\n",
        "- Dense layer with 10 output units\n",
        "- Softmax activation\n",
        "\n",
        "We use fewer classes (10 instead of 1000).\n",
        "\n",
        "### 3. Freeze Base Layers\n",
        "- Pre-trained weights are not updated\n",
        "- Only the new classifier trains first\n",
        "- Later fine-tuning can be applied"
      ],
      "metadata": {
        "id": "J_0eMYxtla5c"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GPIsJEiDjGI_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}